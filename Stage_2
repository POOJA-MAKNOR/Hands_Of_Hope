import os
import yaml
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from tensorflow.keras import layers, models
import json

Proprocessing

# Load and preprocess data
def load_data(directory):
    data = []
    labels = []
    
    for filename in os.listdir(directory):
        if filename.endswith(".yml"):
            with open(os.path.join(directory, filename), 'r') as yaml_file:
                hand_data = yaml.safe_load(yaml_file)
                landmarks = [point['x'] for point in hand_data['hand_landmarks']]
                data.append(landmarks)
                labels.append(directory.split("/")[-1])  # Assuming the class label is the last part of the directory

    return np.array(data), labels

# Prepare dataset
signs_dir = "Signs"
classes = os.listdir(signs_dir)
all_data = []
all_labels = []
# Convert list to dictionary
my_dict = {i: classes[i] for i in range(len(classes))}

# Save the dictionary to a JSON file
with open('labels_info.json', 'w') as json_file:
    json.dump(my_dict, json_file)
print(all_labels)
print(classes)
for sign_class in classes:
    data, labels = load_data(os.path.join(signs_dir, sign_class))
    all_data.extend(data)
    all_labels.extend(labels)

# Convert labels to integers
label_to_int = {label: i for i, label in enumerate(set(all_labels))}
print(label_to_int)
all_labels = [label_to_int[label] for label in all_labels]
print(all_labels)

print(label_to_int)

all_data
# Convert data to numpy array
X_data = np.array(all_data)
y_labels = np.array(all_labels)

# Split the dataset
X_train, X_test, y_train, y_test = train_test_split(X_data, y_labels, test_size=0.2, random_state=42)

# Build the model
model = models.Sequential([
    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
    layers.Dense(64, activation='relu'),
    layers.Dense(len(set(all_labels)), activation='softmax')
])

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))

# Evaluate the model
test_loss, test_acc = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {test_acc}")

# Save the model and label mapping
model.save('sign_language_model.h5')

# Create a dictionary mapping class labels to class names
label_to_class_name = {label_to_int[label]: label for label in label_to_int}

label_to_class_name

# Save the label mapping to a JSON file
with open('label_mapping.json', 'w') as json_file:
    json.dump(label_to_class_name, json_file)

# Load the trained model
model = tf.keras.models.load_model('sign_language_model.h5')

# Load the label information from the JSON file
with open('label_mapping.json', 'r') as json_file:
    label_mapping = json.load(json_file)

# Path to your test landmarks YAML file
test_landmarks_path = 'Signs/Fine/left_9.yml'  # Replace with the path to your test landmarks YAML file


# Function to preprocess hand landmarks
def preprocess_hand_landmarks(hand_landmarks):
    landmarks = [point['x'] for point in hand_landmarks['hand_landmarks']]
    return np.array(landmarks)


# Load hand landmarks data from YAML file
with open(test_landmarks_path, 'r') as yaml_file:
    hand_landmarks_data = yaml.safe_load(yaml_file)

# Preprocess hand landmarks
hand_landmarks_processed = preprocess_hand_landmarks(hand_landmarks_data)

# Resize the data to match the input size expected by the model
hand_landmarks_resized = np.expand_dims(hand_landmarks_processed, axis=0)


# Make prediction
prediction = model.predict(hand_landmarks_resized)
predicted_class = np.argmax(prediction)
print(predicted_class)

# Map the predicted class to its corresponding class name
predicted_class_name = label_mapping.get(str(predicted_class), "Unknown")

# Extract only the last part of the path (class name)
predicted_class_name = os.path.basename(predicted_class_name)

# Display the predicted class name
print(f"Predicted Class Name: {predicted_class_name}")





























